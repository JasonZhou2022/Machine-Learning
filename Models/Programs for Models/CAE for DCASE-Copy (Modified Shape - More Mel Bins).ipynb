{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6049d3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1997f91b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#loading data\n",
    "data = np.load(\"normalizedCutExpandedDATA.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6f6cd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking a sample size of 10,000\n",
    "#8:2 split (training_data:testing_data ratio)\n",
    "np.random.shuffle(data)\n",
    "training_data = data[:8000] #length of 8000\n",
    "testing_data = data[8000:10000] #length of 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f7f0b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fd26e191",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential( #starting size: (100,431)\n",
    "            nn.Conv2d(1,32,5), #input: 100, 431 -> 96,427\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,32,7), #input: 48, 213 -> 42,207\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,64,8), #input: 21, 103 -> 14,96\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2), #input: 14, 96 -> 7, 48\n",
    "            #final: 1, 106\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 48, 3, stride=1), #input: 7,48 -> 9,50\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(48, 32, 7, stride=2), #input: 9,50 -> 23,105\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 6, stride=2), #input: 23, 105 -> 50, 214\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, 5, stride=2), #input: 50, 214 -> 103, 431\n",
    "            \n",
    "            #final: 10,431\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.encoder(x)\n",
    "        x=self.decoder(x)\n",
    "        x = x[:,:,:100,:]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fda8e776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Shape: 250, 32\n"
     ]
    }
   ],
   "source": [
    "#creating the batches\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "BATCHES = []\n",
    "\n",
    "copy = training_data.tolist()\n",
    "\n",
    "iterations = int((len(copy))/BATCH_SIZE)\n",
    "for i in range(iterations):\n",
    "    start = random.randint(0, len(copy) - BATCH_SIZE)\n",
    "    end = start + BATCH_SIZE\n",
    "    batch = copy[start:end]\n",
    "    BATCHES.append(batch)\n",
    "    copy = copy[:start] + copy[end:] #taking out the batch from the training_data\n",
    "    #to prevent duplicate numbers from appearing across batches\n",
    "   \n",
    "print(len(copy))\n",
    "print(f'Shape: {len(BATCHES)}, {len(BATCHES[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1ac96f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the python list to tensor\n",
    "\n",
    "batched_training_data = np.array(BATCHES)\n",
    "batched_training_data = torch.from_numpy(batched_training_data).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "74b30739",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JasonZhou\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([32, 100, 431])) that is different to the input size (torch.Size([32, 1, 100, 431])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 89.8978\n",
      "Epoch 1, Loss: 70.6342\n",
      "Epoch 2, Loss: 63.3134\n",
      "Epoch 3, Loss: 59.1917\n",
      "Epoch 4, Loss: 56.3926\n",
      "Epoch 5, Loss: 53.5761\n",
      "Epoch 6, Loss: 50.8648\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-68c6b2af9c89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNUM_OF_EPOCH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatched_training_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatched_training_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m431\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatched_training_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-e8d9e4124a32>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, output_size)\u001b[0m\n\u001b[0;32m    921\u001b[0m             input, output_size, self.stride, self.padding, self.kernel_size, self.dilation)  # type: ignore[arg-type]\n\u001b[0;32m    922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 923\u001b[1;33m         return F.conv_transpose2d(\n\u001b[0m\u001b[0;32m    924\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m             output_padding, self.groups, self.dilation)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#training\n",
    "\n",
    "model = CAE()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.0001)\n",
    "\n",
    "NUM_OF_EPOCH = 250\n",
    "\n",
    "outputs = []\n",
    "\n",
    "for epoch in range(NUM_OF_EPOCH):\n",
    "    for i in range(len(batched_training_data)):\n",
    "        output = model(batched_training_data[i].view(-1,1,100,431))\n",
    "        loss = criterion(output, batched_training_data[i])\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    outputs.append((epoch, output, batched_training_data[i]))\n",
    "    print(f'Epoch {epoch}, Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812acd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(batched_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bd260e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.load(\"control.npy\")\n",
    "t = t[:, :431]\n",
    "mspecTensor = torch.from_numpy(t) \n",
    "mspecTensor = model(mspecTensor.view(-1,1,100,431))\n",
    "show = (t, mspecTensor)\n",
    "\n",
    "plt.figure(figsize=(25,10))\n",
    "librosa.display.specshow(show[0], x_axis = \"time\", y_axis = \"mel\", sr=22050)\n",
    "#librosa.display.specshow(show[0].view(10,474).detach().numpy(), x_axis = \"time\", y_axis = \"mel\", sr=22050)\n",
    "\n",
    "plt.colorbar(format=\"%+2.f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fe8100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc40313",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,10))\n",
    "#librosa.display.specshow(show[0], x_axis = \"time\", y_axis = \"mel\", sr=22050)\n",
    "librosa.display.specshow(show[1].view(100,431).detach().numpy(), x_axis = \"time\", y_axis = \"mel\", sr=22050)\n",
    "\n",
    "plt.colorbar(format=\"%+2.f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87c9b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"controlResult4.npy\", show[1].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c25eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "controlResult = np.load(\"controlResult.npy\")\n",
    "plt.figure(figsize=(25,10))\n",
    "librosa.display.specshow(controlResult.reshape(100,474), x_axis = \"time\", y_axis = \"mel\", sr=22050)\n",
    "\n",
    "plt.colorbar(format=\"%+2.f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e9521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#might as well save what I have done\n",
    "\n",
    "# path = \"C:\\\\Users\\\\JasonZhou\\\\Models\"\n",
    "# torch.save(model, path)\n",
    "\n",
    "import pickle\n",
    "\n",
    "filename = 'model_7.pt'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a723ecf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# controlResult = np.load(\"controlResult.npy\")\n",
    "plt.figure(figsize=(25,10))\n",
    "librosa.display.specshow(testing_data[0].reshape(100,431), x_axis = \"time\", y_axis = \"mel\", sr=22050)\n",
    "\n",
    "plt.colorbar(format=\"%+2.f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5524ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pic = testing_data[0]\n",
    "pic = pic[:, :431]\n",
    "o = torch.from_numpy(pic)\n",
    "o = model(o.view(-1,1,100,431))\n",
    "plt.figure(figsize=(25,10))\n",
    "librosa.display.specshow(o.view(100,431).detach().numpy(), x_axis = \"time\", y_axis = \"mel\", sr=22050)\n",
    "\n",
    "plt.colorbar(format=\"%+2.f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81897ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
